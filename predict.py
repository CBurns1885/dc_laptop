#!/usr/bin/env python3
"""
ULTIMATE predict.py - Maximum Accuracy Prediction Engine
Combines:
- League-specific calibration
- Cross-market mathematical constraints
- Poisson statistical adjustments
- Time-weighted recent form
- Dynamic blend weights by league quality
- Confidence scoring with model agreement
- Enhanced HTML reporting
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import json
from scipy.stats import poisson
from datetime import datetime, timedelta

from config import FEATURES_PARQUET, OUTPUT_DIR, MODEL_ARTIFACTS_DIR, log_header
from models import load_trained_targets, predict_proba as model_predict
from dc_predict import build_dc_for_fixtures
from progress_utils import heartbeat
from blending import BLEND_WEIGHTS_JSON

ID_COLS = ["League","Date","HomeTeam","AwayTeam"]
OU_LINES = ["0_5","1_5","2_5","3_5","4_5","5_5"]
# AH_LINES removed - DC-only BTTS and O/U

# League scoring profiles (learned from historical data)
LEAGUE_PROFILES = {
    'E0': {'avg_goals': 2.72, 'home_adv': 0.12, 'btts_rate': 0.53, 'over25_rate': 0.52, 'quality': 'elite'},
    'E1': {'avg_goals': 2.65, 'home_adv': 0.10, 'btts_rate': 0.51, 'over25_rate': 0.50, 'quality': 'high'},
    'E2': {'avg_goals': 2.58, 'home_adv': 0.11, 'btts_rate': 0.49, 'over25_rate': 0.48, 'quality': 'medium'},
    'E3': {'avg_goals': 2.61, 'home_adv': 0.13, 'btts_rate': 0.50, 'over25_rate': 0.49, 'quality': 'medium'},
    'EC': {'avg_goals': 2.65, 'home_adv': 0.12, 'btts_rate': 0.51, 'over25_rate': 0.50, 'quality': 'medium'},
    'SP1': {'avg_goals': 2.48, 'home_adv': 0.15, 'btts_rate': 0.46, 'over25_rate': 0.45, 'quality': 'elite'},
    'SP2': {'avg_goals': 2.35, 'home_adv': 0.14, 'btts_rate': 0.43, 'over25_rate': 0.41, 'quality': 'high'},
    'I1': {'avg_goals': 2.68, 'home_adv': 0.11, 'btts_rate': 0.52, 'over25_rate': 0.51, 'quality': 'elite'},
    'I2': {'avg_goals': 2.45, 'home_adv': 0.12, 'btts_rate': 0.47, 'over25_rate': 0.44, 'quality': 'high'},
    'D1': {'avg_goals': 3.05, 'home_adv': 0.09, 'btts_rate': 0.58, 'over25_rate': 0.60, 'quality': 'elite'},
    'D2': {'avg_goals': 2.85, 'home_adv': 0.10, 'btts_rate': 0.55, 'over25_rate': 0.56, 'quality': 'high'},
    'F1': {'avg_goals': 2.55, 'home_adv': 0.13, 'btts_rate': 0.48, 'over25_rate': 0.47, 'quality': 'elite'},
    'F2': {'avg_goals': 2.42, 'home_adv': 0.12, 'btts_rate': 0.45, 'over25_rate': 0.43, 'quality': 'high'},
    'N1': {'avg_goals': 2.95, 'home_adv': 0.08, 'btts_rate': 0.60, 'over25_rate': 0.59, 'quality': 'high'},
    'B1': {'avg_goals': 2.78, 'home_adv': 0.10, 'btts_rate': 0.54, 'over25_rate': 0.53, 'quality': 'high'},
    'P1': {'avg_goals': 2.52, 'home_adv': 0.16, 'btts_rate': 0.47, 'over25_rate': 0.46, 'quality': 'high'},
    'SC0': {'avg_goals': 2.65, 'home_adv': 0.11, 'btts_rate': 0.51, 'over25_rate': 0.50, 'quality': 'high'},
    'SC1': {'avg_goals': 2.58, 'home_adv': 0.13, 'btts_rate': 0.49, 'over25_rate': 0.48, 'quality': 'medium'},
    'T1': {'avg_goals': 3.10, 'home_adv': 0.14, 'btts_rate': 0.59, 'over25_rate': 0.61, 'quality': 'elite'},
}

def _load_base_features() -> pd.DataFrame:
    """Load historical features with preprocessing"""
    df = pd.read_parquet(FEATURES_PARQUET)
    if not np.issubdtype(df["Date"].dtype, np.datetime64):
        df["Date"] = pd.to_datetime(df["Date"])
    return df.sort_values(["League","Date"])

def calculate_league_profiles(df: pd.DataFrame) -> Dict:
    """Calculate actual league profiles from historical data"""
    profiles = {}
    
    for league in df['League'].unique():
        league_data = df[df['League'] == league]
        if len(league_data) < 50:
            continue
            
        total_goals = league_data['FTHG'].fillna(0) + league_data['FTAG'].fillna(0)
        home_wins = (league_data['FTR'] == 'H').mean()
        away_wins = (league_data['FTR'] == 'A').mean()
        
        profiles[league] = {
            'avg_goals': total_goals.mean(),
            'home_adv': home_wins - away_wins,
            'btts_rate': ((league_data['FTHG'] > 0) & (league_data['FTAG'] > 0)).mean(),
            'over25_rate': (total_goals > 2.5).mean(),
            'over15_rate': (total_goals > 1.5).mean(),
            'over35_rate': (total_goals > 3.5).mean(),
            'over45_rate': (total_goals > 4.5).mean(),
        }
    
    return profiles

def apply_league_calibration(prob: float, market: str, league: str, league_profiles: Dict) -> float:
    """Calibrate probability based on league-specific patterns"""
    if league not in league_profiles:
        return prob
    
    profile = league_profiles[league]
    
    # Stronger calibration for lower confidence predictions
    confidence = abs(prob - 0.5) * 2  # 0 to 1 scale
    calibration_weight = 0.3 * (1 - confidence)  # More calibration when less confident
    
    if 'BTTS_Y' in market:
        league_avg = profile.get('btts_rate', 0.5)
        return prob * (1 - calibration_weight) + league_avg * calibration_weight
    
    elif 'OU_0_5_O' in market:
        return min(prob * 1.05, 0.99)  # Boost slightly (0.5 goals is very likely)
    
    elif 'OU_1_5_O' in market:
        league_avg = profile.get('over15_rate', 0.7)
        return prob * (1 - calibration_weight * 0.5) + league_avg * (calibration_weight * 0.5)
    
    elif 'OU_2_5_O' in market:
        league_avg = profile.get('over25_rate', 0.5)
        return prob * (1 - calibration_weight) + league_avg * calibration_weight
    
    elif 'OU_3_5_O' in market:
        league_avg = profile.get('over35_rate', 0.25)
        return prob * (1 - calibration_weight) + league_avg * calibration_weight
    
    elif 'OU_4_5_O' in market:
        league_avg = profile.get('over45_rate', 0.15)
        return prob * (1 - calibration_weight) + league_avg * calibration_weight
    
    elif '1X2_H' in market:
        home_adv = profile.get('home_adv', 0.1)
        return min(prob * (1 + home_adv * 0.25), 0.95)
    
    elif '1X2_A' in market:
        home_adv = profile.get('home_adv', 0.1)
        return max(prob * (1 - home_adv * 0.25), 0.05)
    
    return prob

def enforce_cross_market_constraints(row: pd.Series) -> pd.Series:
    """Ensure mathematical consistency between related markets"""
    row = row.copy()
    
    # 1. O/U probabilities must be monotonically decreasing
    if all(f'P_OU_{line}_O' in row for line in OU_LINES):
        for i in range(len(OU_LINES) - 1):
            curr_line = OU_LINES[i]
            next_line = OU_LINES[i + 1]
            curr_col = f'P_OU_{curr_line}_O'
            next_col = f'P_OU_{next_line}_O'
            
            if pd.notna(row[curr_col]) and pd.notna(row[next_col]):
                if row[curr_col] < row[next_col]:
                    avg = (row[curr_col] + row[next_col]) / 2
                    row[curr_col] = min(avg + 0.05, 0.99)
                    row[next_col] = max(avg - 0.05, 0.01)
                
                # Update Under probabilities
                row[f'P_OU_{curr_line}_U'] = 1 - row[curr_col]
                row[f'P_OU_{next_line}_U'] = 1 - row[next_col]
    
    # 2. BTTS and O/U 0.5 logical consistency
    if 'P_BTTS_Y' in row and 'P_OU_0_5_U' in row:
        if pd.notna(row['P_BTTS_Y']) and pd.notna(row['P_OU_0_5_U']):
            # BTTS=Yes implies Over 0.5 must be very high
            if row['P_BTTS_Y'] > 0.7:
                row['P_OU_0_5_U'] = min(row['P_OU_0_5_U'], 0.02)
                row['P_OU_0_5_O'] = max(row['P_OU_0_5_O'], 0.98)
            
            # Under 0.5 high means BTTS=Yes must be zero
            if row['P_OU_0_5_U'] > 0.5:
                row['P_BTTS_Y'] = 0.0
                row['P_BTTS_N'] = 1.0
    
    # 3. BTTS and O/U 1.5 consistency
    if 'P_BTTS_Y' in row and 'P_OU_1_5_O' in row:
        if pd.notna(row['P_BTTS_Y']) and pd.notna(row['P_OU_1_5_O']):
            # BTTS=Yes requires at least 2 goals (Over 1.5)
            if row['P_BTTS_Y'] > 0.6:
                row['P_OU_1_5_O'] = max(row['P_OU_1_5_O'], row['P_BTTS_Y'] * 0.9)
                row['P_OU_1_5_U'] = 1 - row['P_OU_1_5_O']
    
    # 4. 1X2 probabilities sum to 1.0
    if all(f'P_1X2_{x}' in row for x in ['H', 'D', 'A']):
        if all(pd.notna(row[f'P_1X2_{x}']) for x in ['H', 'D', 'A']):
            total = row['P_1X2_H'] + row['P_1X2_D'] + row['P_1X2_A']
            if total > 0:
                row['P_1X2_H'] /= total
                row['P_1X2_D'] /= total
                row['P_1X2_A'] /= total
    
    # 5. Correct Score 0-0 cannot exceed Under 0.5
    if 'P_CS_0_0' in row and 'P_OU_0_5_U' in row:
        if pd.notna(row['P_CS_0_0']) and pd.notna(row['P_OU_0_5_U']):
            row['P_CS_0_0'] = min(row['P_CS_0_0'], row['P_OU_0_5_U'])
    
    # 6. Team goals and BTTS consistency
    if all(col in row for col in ['P_BTTS_Y', 'P_HomeTG_0_5_O', 'P_AwayTG_0_5_O']):
        if all(pd.notna(row[col]) for col in ['P_BTTS_Y', 'P_HomeTG_0_5_O', 'P_AwayTG_0_5_O']):
            # BTTS requires both teams to score
            min_btts = row['P_HomeTG_0_5_O'] * row['P_AwayTG_0_5_O']
            row['P_BTTS_Y'] = max(row['P_BTTS_Y'], min_btts * 0.85)
            row['P_BTTS_N'] = 1 - row['P_BTTS_Y']
    
    return row

def apply_poisson_adjustment(row: pd.Series, home_xg: float = None, away_xg: float = None, league: str = None) -> pd.Series:
    """Apply Poisson distribution for goal-based markets"""
    row = row.copy()
    
    # Use league-specific or default xG
    if league and league in LEAGUE_PROFILES:
        profile = LEAGUE_PROFILES[league]
        total_expected = profile['avg_goals']
        home_share = 0.54  # Home advantage ~54% of goals
        home_xg = home_xg or (total_expected * home_share)
        away_xg = away_xg or (total_expected * (1 - home_share))
    else:
        home_xg = home_xg or 1.4
        away_xg = away_xg or 1.1
    
    total_xg = home_xg + away_xg
    
    # Calculate Poisson probabilities for O/U lines
    for line in OU_LINES:
        line_value = float(line.replace('_', '.'))
        
        # Poisson probability of over this line
        poisson_over = 1 - poisson.cdf(line_value, total_xg)
        
        # Adaptive blending based on line
        if line == '0_5':
            blend_weight = 0.3  # Less Poisson influence (nearly always over)
        elif line == '1_5':
            blend_weight = 0.4
        elif line == '2_5':
            blend_weight = 0.5  # Equal blend
        elif line == '3_5':
            blend_weight = 0.4
        else:  # 4_5
            blend_weight = 0.3
        
        if f'P_OU_{line}_O' in row and pd.notna(row[f'P_OU_{line}_O']):
            row[f'P_OU_{line}_O'] = row[f'P_OU_{line}_O'] * (1 - blend_weight) + poisson_over * blend_weight
            row[f'P_OU_{line}_U'] = 1 - row[f'P_OU_{line}_O']
    
    # BTTS using Poisson
    prob_home_scores = 1 - poisson.pmf(0, home_xg)
    prob_away_scores = 1 - poisson.pmf(0, away_xg)
    poisson_btts = prob_home_scores * prob_away_scores
    
    if 'P_BTTS_Y' in row and pd.notna(row['P_BTTS_Y']):
        row['P_BTTS_Y'] = row['P_BTTS_Y'] * 0.65 + poisson_btts * 0.35
        row['P_BTTS_N'] = 1 - row['P_BTTS_Y']
    
    return row

def _build_future_frame(fixtures_csv: Path) -> pd.DataFrame:
    """Enhanced feature building with time weighting"""
    base = _load_base_features()
    fx = pd.read_csv(fixtures_csv)
    fx["Date"] = pd.to_datetime(fx["Date"])
    
    # Add time weights for recent form emphasis
    current_date = datetime.now()
    base['days_ago'] = (current_date - pd.to_datetime(base['Date'])).dt.days
    base['time_weight'] = np.exp(-base['days_ago'] / 180)  # 180-day half-life
    
    rows = []
    for _, r in fx.iterrows():
        lg, dt, ht, at = r["League"], r["Date"], r["HomeTeam"], r["AwayTeam"]
        hist_lg = base[base["League"] == lg]
        
        # Get last 10 games for each team with time weighting
        hrow = hist_lg[(hist_lg["HomeTeam"]==ht) | (hist_lg["AwayTeam"]==ht)]
        hrow = hrow[hrow["Date"]<dt].sort_values("Date").tail(10)
        
        arow = hist_lg[(hist_lg["HomeTeam"]==at) | (hist_lg["AwayTeam"]==at)]
        arow = arow[arow["Date"]<dt].sort_values("Date").tail(10)
        
        if hrow.empty or arow.empty:
            continue
        
        feat_cols = [c for c in base.columns if not c.startswith("y_") 
                     and c not in ["FTHG","FTAG","FTR","HTHG","HTAG","HTR","days_ago","time_weight"]]
        
        fused = pd.DataFrame()
        
        # Calculate weighted features for home team
        for col in feat_cols:
            if col in hrow.columns and hrow[col].dtype in ['float64', 'int64']:
                weights = hrow['time_weight'].values[-5:]
                values = hrow[col].fillna(0).values[-5:]
                if weights.sum() > 0:
                    weighted_avg = np.average(values, weights=weights)
                    fused.at[0, col] = weighted_avg
                else:
                    fused.at[0, col] = hrow[col].iloc[-1] if len(hrow) > 0 else 0
            else:
                fused.at[0, col] = hrow[col].iloc[-1] if len(hrow) > 0 else 0
        
        # Update away team features
        for c in fused.columns:
            if c.startswith("Away_") and c in arow.columns:
                if arow[c].dtype in ['float64', 'int64']:
                    weights = arow['time_weight'].values[-5:]
                    values = arow[c].fillna(0).values[-5:]
                    if weights.sum() > 0:
                        weighted_avg = np.average(values, weights=weights)
                        fused.at[0, c] = weighted_avg
                else:
                    fused.at[0, c] = arow[c].iloc[-1] if len(arow) > 0 else 0
        
        fused["League"] = lg
        fused["Date"] = dt
        fused["HomeTeam"] = ht
        fused["AwayTeam"] = at
        
        for c in base.columns:
            if c.startswith("y_"):
                fused[c] = pd.NA
        
        rows.append(fused)
    
    if not rows:
        raise RuntimeError("No fixtures matched with historical features.")
    
    return pd.concat(rows, ignore_index=True).sort_values(["League","Date","HomeTeam"])

def _collect_market_columns() -> List[str]:
    """All expected probability column names"""
    cols = ["P_1X2_H","P_1X2_D","P_1X2_A","P_BTTS_Y","P_BTTS_N"]
    
    for l in OU_LINES:
        cols += [f"P_OU_{l}_O", f"P_OU_{l}_U"]
    
    for l in AH_LINES:
        cols += [f"P_AH_{l}_H", f"P_AH_{l}_A", f"P_AH_{l}_P"]
    
    cols += [f"P_GR_{k}" for k in ["0","1","2","3","4","5+"]]
    cols += ["P_HT_H","P_HT_D","P_HT_A"]
    cols += [f"P_HTFT_{a}_{b}" for a in ["H","D","A"] for b in ["H","D","A"]]
    
    for l in ["0_5","1_5","2_5","3_5"]:
        cols += [f"P_HomeTG_{l}_O",f"P_HomeTG_{l}_U",f"P_AwayTG_{l}_O",f"P_AwayTG_{l}_U"]
    
    cols += [f"P_HomeCardsY_{b}" for b in ["0-2","3","4-5","6+"]]
    cols += [f"P_AwayCardsY_{b}" for b in ["0-2","3","4-5","6+"]]
    
    cols += [f"P_HomeCorners_{b}" for b in ["0-3","4-5","6-7","8-9","10+"]]
    cols += [f"P_AwayCorners_{b}" for b in ["0-3","4-5","6-7","8-9","10+"]]
    
    for i in range(6):
        for j in range(6):
            cols.append(f"P_CS_{i}_{j}")
    cols.append("P_CS_Other")
    
    return cols

def _map_preds_to_columns(models, preds: dict, fixtures_df: pd.DataFrame = None) -> Tuple[List[dict], List[str]]:
    """Enhanced mapping with all improvements"""
    out_cols = _collect_market_columns()
    n_rows = next(iter(preds.values())).shape[0] if preds else 0
    rows = []
    
    # Calculate league profiles
    base_features = _load_base_features()
    league_profiles = calculate_league_profiles(base_features)
    
    class_maps = {t: list(m.classes_) for t, m in models.items()}
    
    def labmap(t):
        return {lab: i for i, lab in enumerate(class_maps.get(t, []))}
    
    def pick(p, t, label):
        if t not in class_maps:
            return 0.0
        m = labmap(t)
        return float(p[m[label]]) if label in m else 0.0
    
    for i in range(n_rows):
        row = {}
        
        # Get fixture info
        league = fixtures_df.iloc[i]['League'] if fixtures_df is not None and 'League' in fixtures_df.columns else None
        
        # Initialize
        for col in out_cols:
            row[col] = 0.0
        
        # Map predictions (same as predict2.py)
        if "y_1X2" in preds:
            p = preds["y_1X2"][i]
            row["P_1X2_H"] = pick(p, "y_1X2", "H")
            row["P_1X2_D"] = pick(p, "y_1X2", "D")
            row["P_1X2_A"] = pick(p, "y_1X2", "A")
        
        if "y_BTTS" in preds:
            p = preds["y_BTTS"][i]
            row["P_BTTS_Y"] = pick(p, "y_BTTS", "Y")
            row["P_BTTS_N"] = pick(p, "y_BTTS", "N")
        
        for l in OU_LINES:
            key = f"y_OU_{l}"
            if key in preds:
                p = preds[key][i]
                row[f"P_OU_{l}_O"] = pick(p, key, "O")
                row[f"P_OU_{l}_U"] = pick(p, key, "U")
        
        for l in AH_LINES:
            key = f"y_AH_{l}"
            if key in preds:
                p = preds[key][i]
                row[f"P_AH_{l}_H"] = pick(p, key, "H")
                row[f"P_AH_{l}_A"] = pick(p, key, "A")
                row[f"P_AH_{l}_P"] = pick(p, key, "P")
        
        if "y_GOAL_RANGE" in preds:
            p = preds["y_GOAL_RANGE"][i]
            for k in ["0","1","2","3","4","5+"]:
                row[f"P_GR_{k}"] = pick(p, "y_GOAL_RANGE", k)
        
        if "y_HT" in preds:
            p = preds["y_HT"][i]
            row["P_HT_H"] = pick(p, "y_HT", "H")
            row["P_HT_D"] = pick(p, "y_HT", "D")
            row["P_HT_A"] = pick(p, "y_HT", "A")
        
        if "y_HTFT" in preds:
            p = preds["y_HTFT"][i]
            for a in ["H","D","A"]:
                for b in ["H","D","A"]:
                    row[f"P_HTFT_{a}_{b}"] = pick(p, "y_HTFT", f"{a}-{b}")
        
        for l in ["0_5","1_5","2_5","3_5"]:
            hk = f"y_HomeTG_{l}"
            ak = f"y_AwayTG_{l}"
            if hk in preds:
                p = preds[hk][i]
                row[f"P_HomeTG_{l}_O"] = pick(p, hk, "O")
                row[f"P_HomeTG_{l}_U"] = pick(p, hk, "U")
            if ak in preds:
                p = preds[ak][i]
                row[f"P_AwayTG_{l}_O"] = pick(p, ak, "O")
                row[f"P_AwayTG_{l}_U"] = pick(p, ak, "U")
        
        if "y_HomeCardsY_BAND" in preds:
            p = preds["y_HomeCardsY_BAND"][i]
            for b in ["0-2","3","4-5","6+"]:
                row[f"P_HomeCardsY_{b}"] = pick(p, "y_HomeCardsY_BAND", b)
        
        if "y_AwayCardsY_BAND" in preds:
            p = preds["y_AwayCardsY_BAND"][i]
            for b in ["0-2","3","4-5","6+"]:
                row[f"P_AwayCardsY_{b}"] = pick(p, "y_AwayCardsY_BAND", b)
        
        if "y_HomeCorners_BAND" in preds:
            p = preds["y_HomeCorners_BAND"][i]
            for b in ["0-3","4-5","6-7","8-9","10+"]:
                row[f"P_HomeCorners_{b}"] = pick(p, "y_HomeCorners_BAND", b)
        
        if "y_AwayCorners_BAND" in preds:
            p = preds["y_AwayCorners_BAND"][i]
            for b in ["0-3","4-5","6-7","8-9","10+"]:
                row[f"P_AwayCorners_{b}"] = pick(p, "y_AwayCorners_BAND", b)
        
        if "y_CS" in preds:
            p = preds["y_CS"][i]
            for a in range(6):
                for b in range(6):
                    row[f"P_CS_{a}_{b}"] = pick(p, "y_CS", f"{a}-{b}")
            row["P_CS_Other"] = pick(p, "y_CS", "Other")
        
        # Apply league calibration
        if league and league_profiles:
            for market in row.keys():
                if market.startswith('P_') and pd.notna(row[market]):
                    row[market] = apply_league_calibration(
                        row[market], market, league, league_profiles
                    )
        
        # Convert to series
        row_series = pd.Series(row)
        
        # Apply Poisson adjustments
        row_series = apply_poisson_adjustment(row_series, league=league)
        
        # Enforce cross-market constraints
        row_series = enforce_cross_market_constraints(row_series)
        
        rows.append(row_series.to_dict())
    
    return rows, out_cols

def _apply_blend(out: pd.DataFrame) -> pd.DataFrame:
    """Enhanced blending with dynamic weights by league quality"""
    try:
        if not BLEND_WEIGHTS_JSON.exists():
            heartbeat("Blend weights file missing; skipping BLEND_* columns.")
            return out
        
        weights = json.loads(BLEND_WEIGHTS_JSON.read_text())
        if not weights:
            heartbeat("No blend weights found; skipping BLEND_* columns.")
            return out
    except Exception as e:
        heartbeat(f"Error loading blend weights: {e}; skipping BLEND_* columns.")
        return out

    def pair_cols_for_target(target: str) -> Tuple[List[str], List[str]]:
        if target == "y_1X2":
            ml_cols = ["P_1X2_H","P_1X2_D","P_1X2_A"]
            dc_cols = ["DC_1X2_H","DC_1X2_D","DC_1X2_A"]
        elif target == "y_BTTS":
            ml_cols = ["P_BTTS_N","P_BTTS_Y"]
            dc_cols = ["DC_BTTS_N","DC_BTTS_Y"]
        elif target == "y_GOAL_RANGE":
            ml_cols = [f"P_GR_{k}" for k in ["0","1","2","3","4","5+"]]
            dc_cols = [f"DC_GR_{k}" for k in ["0","1","2","3","4","5+"]]
        elif target == "y_CS":
            ml_cols = [f"P_CS_{a}_{b}" for a in range(6) for b in range(6)] + ["P_CS_Other"]
            dc_cols = [f"DC_CS_{a}_{b}" for a in range(6) for b in range(6)] + ["DC_CS_Other"]
        elif target.startswith("y_OU_"):
            line_part = target.replace("y_OU_", "")
            ml_cols = [f"P_OU_{line_part}_U", f"P_OU_{line_part}_O"]
            dc_cols = [f"DC_OU_{line_part}_U", f"DC_OU_{line_part}_O"]
        elif target.startswith("y_AH_"):
            line_part = target.replace("y_AH_", "")
            ml_cols = [f"P_AH_{line_part}_A", f"P_AH_{line_part}_P", f"P_AH_{line_part}_H"]
            dc_cols = [f"DC_AH_{line_part}_A", f"DC_AH_{line_part}_P", f"DC_AH_{line_part}_H"]
        else:
            return [], []
        return ml_cols, dc_cols

    print("Creating enhanced BLEND predictions with dynamic weights...")
    
    # Apply blending row by row with league-specific adjustments
    for idx in range(len(out)):
        league = out.iloc[idx]['League'] if 'League' in out.columns else None
        
        # Determine ML weight adjustment based on league quality
        ml_weight_boost = 0.0
        if league in LEAGUE_PROFILES:
            quality = LEAGUE_PROFILES[league].get('quality', 'medium')
            if quality == 'elite':
                ml_weight_boost = 0.15  # Trust ML more in top leagues
            elif quality == 'high':
                ml_weight_boost = 0.10
            elif quality == 'medium':
                ml_weight_boost = 0.05
        
        for target, base_alpha in weights.items():
            ml_cols, dc_cols = pair_cols_for_target(target)
            if not ml_cols:
                continue
            
            missing_ml = [c for c in ml_cols if c not in out.columns]
            missing_dc = [c for c in dc_cols if c not in out.columns]
            
            if missing_ml or missing_dc:
                continue
            
            # Adjust alpha based on league quality
            alpha = min(float(base_alpha) + ml_weight_boost, 0.85)
            
            # Get probabilities
            M = out.loc[idx, ml_cols].values
            D = out.loc[idx, dc_cols].values
            
            # Blend: alpha * ML + (1-alpha) * DC
            B = alpha * M + (1.0 - alpha) * D
            
            # Renormalize
            s = B.sum()
            if s > 0:
                B = B / s
            
            # Create BLEND columns
            blend_cols = [c.replace("P_","BLEND_") for c in ml_cols]
            out.loc[idx, blend_cols] = B
    
    # Apply final cross-market constraints to BLEND columns
    print("Applying cross-market constraints to BLEND predictions...")
    for idx in range(len(out)):
        blend_cols = [c for c in out.columns if c.startswith('BLEND_')]
        if blend_cols:
            blend_row = out.loc[idx, blend_cols]
            renamed = {col: col.replace('BLEND_', 'P_') for col in blend_cols}
            blend_row = blend_row.rename(renamed)
            blend_row = enforce_cross_market_constraints(blend_row)
            
            for old_name, new_name in renamed.items():
                out.at[idx, old_name] = blend_row[new_name]
    
    return out

def calculate_confidence_scores(df: pd.DataFrame) -> pd.DataFrame:
    """Calculate confidence based on model agreement"""
    print("Calculating confidence scores with model agreement...")
    
    for idx in range(len(df)):
        # Key markets to check
        for market in ['1X2_H', '1X2_D', '1X2_A', 'BTTS_Y', 'BTTS_N', 'OU_2_5_O', 'OU_2_5_U']:
            predictions = []
            
            for prefix in ['P_', 'DC_', 'BLEND_']:
                col = f'{prefix}{market}'
                if col in df.columns and pd.notna(df.at[idx, col]):
                    predictions.append(df.at[idx, col])
            
            if len(predictions) >= 2:
                # Confidence = 1 - (standard deviation * 2)
                std_dev = np.std(predictions)
                confidence = max(0, 1 - min(std_dev * 2, 1))
                df.at[idx, f'CONF_{market}'] = confidence
                
                # Also store agreement score (0-100%)
                mean_pred = np.mean(predictions)
                max_deviation = max(abs(p - mean_pred) for p in predictions)
                agreement = max(0, 1 - (max_deviation * 2))
                df.at[idx, f'AGREE_{market}'] = agreement * 100
    
    return df

def _generate_html_for_top(top_df, parse_market_func, title_suffix=""):
    """Generate HTML for a top predictions dataframe"""
    html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1'>
    <title>ðŸŽ¯ ULTIMATE Predictions{title_suffix} - {len(top_df)} Elite Picks</title>
    <style>
        * {{box-sizing: border-box; margin: 0; padding: 0;}}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            color: #333;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }}
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }}
        .header p {{
            font-size: 1.1em;
            opacity: 0.95;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            font-size: 0.95em;
        }}
        thead {{
            background: #f8f9fa;
            position: sticky;
            top: 0;
            z-index: 10;
        }}
        th {{
            padding: 15px 10px;
            text-align: left;
            font-weight: 600;
            color: #495057;
            border-bottom: 2px solid #dee2e6;
        }}
        td {{
            padding: 12px 10px;
            border-bottom: 1px solid #f0f0f0;
        }}
        tr:hover {{
            background-color: #f8f9fa;
        }}
        .elite {{
            background: linear-gradient(90deg, #fff5e6 0%, #ffffff 100%);
            border-left: 4px solid #ff6b35;
        }}
        .high {{
            background: linear-gradient(90deg, #e8f5e9 0%, #ffffff 100%);
            border-left: 4px solid #4caf50;
        }}
        .medium {{
            background: linear-gradient(90deg, #e3f2fd 0%, #ffffff 100%);
            border-left: 4px solid #2196f3;
        }}
        .rank {{
            font-weight: bold;
            color: #667eea;
            font-size: 1.1em;
        }}
        .prob {{
            font-weight: 600;
            color: #2e7d32;
            font-size: 1.05em;
        }}
        .badge {{
            display: inline-block;
            padding: 3px 8px;
            border-radius: 12px;
            font-size: 0.75em;
            font-weight: 600;
            text-transform: uppercase;
        }}
        .badge-blend {{
            background: #667eea;
            color: white;
        }}
        .conf-high {{
            color: #2e7d32;
            font-weight: 600;
        }}
        .conf-med {{
            color: #f57c00;
            font-weight: 600;
        }}
    </style>
</head>
<body>
    <div class='container'>
        <div class='header'>
            <h1>ðŸŽ¯ ULTIMATE PREDICTIONS{title_suffix}</h1>
            <p>{len(top_df)} Elite Picks - Sorted by Confidence & Probability</p>
        </div>
        <table>
            <thead>
                <tr>
                    <th>#</th>
                    <th>Date</th>
                    <th>League</th>
                    <th>Fixture</th>
                    <th>Market</th>
                    <th>Pick</th>
                    <th>Probability</th>
                    <th>Confidence</th>
                </tr>
            </thead>
            <tbody>"""

    for i, (_, r) in enumerate(top_df.iterrows(), 1):
        market, selection = parse_market_func(r['BestMarket'])
        prob = r['BestProb']
        conf = r.get('AvgConfidence', 0.5)

        # Row styling
        if prob >= 0.85 and conf >= 0.75:
            row_class = "elite"
        elif prob >= 0.75:
            row_class = "high"
        elif prob >= 0.65:
            row_class = "medium"
        else:
            row_class = ""

        # Confidence badge
        if conf >= 0.7:
            conf_class = "conf-high"
        else:
            conf_class = "conf-med"

        # Source badge
        source = "BLEND" if r['BestMarket'].startswith("BLEND_") else ("DC" if r['BestMarket'].startswith("DC_") else "ML")

        html += f"""
                <tr class='{row_class}'>
                    <td class='rank'>{i}</td>
                    <td>{str(r['Date']).split()[0]}</td>
                    <td><strong>{r['League']}</strong></td>
                    <td>{r['HomeTeam']}<br><small>vs {r['AwayTeam']}</small></td>
                    <td>{market}</td>
                    <td>{selection} <span class='badge badge-blend'>{source}</span></td>
                    <td class='prob'>{prob:.1%}</td>
                    <td class='{conf_class}'>{conf:.1%}</td>
                </tr>"""

    html += """
            </tbody>
        </table>
    </div>
</body>
</html>"""

    return html

def _write_enhanced_html(df: pd.DataFrame, path: Path, secondary_path: Path = None):
    """Enhanced HTML report with confidence scores"""
    prob_cols = [c for c in df.columns if c.startswith("BLEND_") or c.startswith("P_") or c.startswith("DC_")]
    if not prob_cols:
        print("Warning: No probability columns found")
        return
    
    df2 = df.copy()
    df2["BestProb"] = df2[prob_cols].max(axis=1)
    df2["BestMarket"] = df2[prob_cols].idxmax(axis=1)
    
    # Add confidence if available
    conf_cols = [c for c in df2.columns if c.startswith("CONF_")]
    if conf_cols:
        df2["AvgConfidence"] = df2[conf_cols].mean(axis=1)
    else:
        df2["AvgConfidence"] = 0.5
    
    # Filter meaningful predictions
    meaningful = df2[(df2["BestProb"] > 0.5) & (df2["AvgConfidence"] > 0.5)]
    
    if len(meaningful) >= 10:
        top = meaningful.sort_values(["AvgConfidence", "BestProb"], ascending=[False, False]).head(50)
    else:
        top = df2.sort_values("BestProb", ascending=False).head(50)

    # Also create a version excluding O/U 0.5 markets
    ou_05_columns = [c for c in prob_cols if 'OU_0_5' in c]
    if ou_05_columns:
        df_no_ou05 = df2.copy()
        # Set O/U 0.5 probabilities to 0 so they won't be selected as BestMarket
        for col in ou_05_columns:
            df_no_ou05[col] = 0
        df_no_ou05["BestProb"] = df_no_ou05[prob_cols].max(axis=1)
        df_no_ou05["BestMarket"] = df_no_ou05[prob_cols].idxmax(axis=1)

        # Recalculate AvgConfidence excluding O/U 0.5
        if conf_cols:
            df_no_ou05["AvgConfidence"] = df_no_ou05[conf_cols].mean(axis=1)

        meaningful_no_ou05 = df_no_ou05[(df_no_ou05["BestProb"] > 0.5) & (df_no_ou05["AvgConfidence"] > 0.5)]

        if len(meaningful_no_ou05) >= 10:
            top_no_ou05 = meaningful_no_ou05.sort_values(["AvgConfidence", "BestProb"], ascending=[False, False]).head(50)
        else:
            top_no_ou05 = df_no_ou05.sort_values("BestProb", ascending=False).head(50)
    else:
        top_no_ou05 = None

    def parse_market(market_name):
        market_name = market_name.replace("BLEND_", "").replace("P_", "").replace("DC_", "")
        
        if "1X2" in market_name:
            if market_name.endswith("_H"): return "1X2", "Home Win"
            elif market_name.endswith("_D"): return "1X2", "Draw"
            elif market_name.endswith("_A"): return "1X2", "Away Win"
        elif "BTTS" in market_name:
            if market_name.endswith("_Y"): return "BTTS", "Yes"
            elif market_name.endswith("_N"): return "BTTS", "No"
        elif "OU_" in market_name:
            parts = market_name.split("_")
            if len(parts) >= 3:
                line = parts[1] + "." + parts[2]
                if market_name.endswith("_O"): return f"O/U {line}", "Over"
                elif market_name.endswith("_U"): return f"O/U {line}", "Under"
        elif "GR_" in market_name:
            goal_range = market_name.split("_")[-1]
            return "Goals", f"{goal_range}"
        elif "CS_" in market_name:
            if market_name.endswith("_Other"): return "Score", "Other"
            parts = market_name.split("_")
            if len(parts) >= 3:
                return "Score", f"{parts[-2]}-{parts[-1]}"
        
        return market_name, ""
    
    # Generate HTML using helper function
    html = _generate_html_for_top(top, parse_market)
    <style>
        * {{box-sizing: border-box; margin: 0; padding: 0;}}
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            color: #333;
        }}
        .container {{
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }}
        .stats {{
            background: #f8f9fa;
            padding: 30px;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            border-bottom: 3px solid #667eea;
        }}
        .stat-box {{
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            text-align: center;
        }}
        .stat-box .number {{
            font-size: 2.5em;
            font-weight: bold;
            color: #667eea;
            margin-bottom: 5px;
        }}
        .stat-box .label {{
            color: #666;
            font-size: 0.9em;
            text-transform: uppercase;
            letter-spacing: 1px;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
        }}
        th, td {{
            padding: 15px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }}
        th {{
            background: #f8f9fa;
            font-weight: 600;
            color: #667eea;
            position: sticky;
            top: 0;
            z-index: 10;
        }}
        tr:hover {{
            background: #f8f9fa;
            transform: scale(1.01);
            transition: all 0.2s;
        }}
        .rank {{
            font-weight: bold;
            color: #667eea;
            font-size: 1.2em;
        }}
        .elite {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-weight: bold;
        }}
        .high {{
            background: #d4edda;
        }}
        .medium {{
            background: #fff3cd;
        }}
        .prob {{
            font-weight: bold;
            font-size: 1.3em;
            color: #dc3545;
        }}
        .confidence {{
            display: inline-block;
            padding: 5px 10px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: bold;
        }}
        .conf-high {{
            background: #28a745;
            color: white;
        }}
        .conf-med {{
            background: #ffc107;
            color: #333;
        }}
        .badge {{
            display: inline-block;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.75em;
            font-weight: bold;
            margin-left: 5px;
        }}
        .badge-blend {{
            background: #667eea;
            color: white;
        }}
        @media print {{
            body {{background: white; padding: 0;}}
            .container {{box-shadow: none;}}
        }}
    </style>
</head>
<body>
    <div class='container'>
        <div class='header'>
            <h1>ðŸŽ¯ ULTIMATE PREDICTIONS</h1>
            <p style='font-size: 1.2em; opacity: 0.9;'>Maximum Accuracy System - Top {len(top)} Elite Picks</p>
        </div>
        
        <div class='stats'>
            <div class='stat-box'>
                <div class='number'>{len(df2)}</div>
                <div class='label'>Total Fixtures</div>
            </div>
            <div class='stat-box'>
                <div class='number'>{len(meaningful)}</div>
                <div class='label'>High Quality</div>
            </div>
            <div class='stat-box'>
                <div class='number'>{df2['BestProb'].max():.0%}</div>
                <div class='label'>Best Probability</div>
            </div>
            <div class='stat-box'>
                <div class='number'>{df2['AvgConfidence'].mean():.0%}</div>
                <div class='label'>Avg Confidence</div>
            </div>
        </div>
        
        <table>
            <thead>
                <tr>
                    <th>Rank</th>
                    <th>Date</th>
                    <th>League</th>
                    <th>Fixture</th>
                    <th>Market</th>
                    <th>Pick</th>
                    <th>Probability</th>
                    <th>Confidence</th>
                </tr>
            </thead>
            <tbody>"""
    
    for i, (_, r) in enumerate(top.iterrows(), 1):
        market, selection = parse_market(r['BestMarket'])
        prob = r['BestProb']
        conf = r.get('AvgConfidence', 0.5)
        
        # Row styling
        if prob >= 0.85 and conf >= 0.75:
            row_class = "elite"
        elif prob >= 0.75:
            row_class = "high"
        elif prob >= 0.65:
            row_class = "medium"
        else:
            row_class = ""
        
        # Confidence badge
        if conf >= 0.7:
            conf_class = "conf-high"
        else:
            conf_class = "conf-med"
        
        # Source badge
        source = "BLEND" if r['BestMarket'].startswith("BLEND_") else ("DC" if r['BestMarket'].startswith("DC_") else "ML")
        
        html += f"""
                <tr class='{row_class}'>
                    <td class='rank'>{i}</td>
                    <td>{str(r['Date']).split()[0]}</td>
                    <td><strong>{r['League']}</strong></td>
                    <td>{r['HomeTeam']}<br><small>vs {r['AwayTeam']}</small></td>
                    <td>{market}</td>
                    <td>{selection} <span class='badge badge-blend'>{source}</span></td>
                    <td class='prob'>{prob:.1%}</td>
                    <td><span class='confidence {conf_class}'>{conf:.0%}</span></td>
                </tr>"""
    
    html += """
            </tbody>
        </table>
    </div>
</body>
</html>"""
    
    out_path = path / "top50_ultimate.html"
    out_path.write_text(html, encoding="utf-8")
    print(f"âœ… Wrote ULTIMATE HTML -> {out_path}")

    if secondary_path:
        secondary_path.mkdir(parents=True, exist_ok=True)
        secondary_out = secondary_path / "top50_ultimate.html"
        secondary_out.write_text(html, encoding="utf-8")
        print(f"âœ… Wrote ULTIMATE HTML (copy) -> {secondary_out}")

    # Generate second version excluding O/U 0.5
    if top_no_ou05 is not None and len(top_no_ou05) > 0:
        html_no_ou05 = _generate_html_for_top(top_no_ou05, parse_market, title_suffix=" (Excluding O/U 0.5)")

        out_path_no_ou05 = path / "top50_ultimate_no_ou05.html"
        out_path_no_ou05.write_text(html_no_ou05, encoding="utf-8")
        print(f"âœ… Wrote ULTIMATE HTML (No O/U 0.5) -> {out_path_no_ou05}")

        if secondary_path:
            secondary_out_no_ou05 = secondary_path / "top50_ultimate_no_ou05.html"
            secondary_out_no_ou05.write_text(html_no_ou05, encoding="utf-8")
            print(f"âœ… Wrote ULTIMATE HTML (No O/U 0.5, copy) -> {secondary_out_no_ou05}")

def predict_week(fixtures_csv: Path) -> Path:
    """ULTIMATE prediction pipeline"""
    
    log_header("ðŸŽ¯ ULTIMATE WEEKLY PREDICTIONS")
    print("Maximum Accuracy Features:")
    print("  â€¢ League-specific calibration")
    print("  â€¢ Cross-market constraints")
    print("  â€¢ Poisson adjustments")
    print("  â€¢ Time-weighted form")
    print("  â€¢ Dynamic blend weights")
    print("  â€¢ Confidence scoring\n")
    
    # Load models
    models = load_trained_targets()
    if not models:
        raise RuntimeError("No trained models found!")
    
    # Load fixtures
    fx = pd.read_csv(fixtures_csv)
    fx["Date"] = pd.to_datetime(fx["Date"])
    
    # Build features
    log_header("BUILD ENHANCED FEATURES")
    df_future = _build_future_frame(fixtures_csv)
    
    # Generate ML predictions
    log_header("GENERATE ML PREDICTIONS")
    preds = model_predict(models, df_future)
    
    # Map predictions with all enhancements
    log_header("APPLY ENHANCEMENTS")
    rows, out_cols = _map_preds_to_columns(models, preds, fx)
    
    # Create output
    df_out = pd.DataFrame(rows, columns=out_cols)
    for col in ID_COLS:
        if col in fx.columns:
            df_out[col] = fx[col].values[:len(df_out)]
    
    # Add DC predictions
    log_header("GENERATE DC PREDICTIONS")
    try:
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
        fixtures_copy = OUTPUT_DIR / "upcoming_fixtures.csv"
        fx.to_csv(fixtures_copy, index=False)
        
        dc_path = build_dc_for_fixtures(fixtures_copy)
        dc_df = pd.read_csv(dc_path)
        
        dc_cols = [c for c in dc_df.columns if c.startswith("DC_")]
        for col in dc_cols:
            if col in dc_df.columns:
                df_out[col] = dc_df[col].values[:len(df_out)]
        
        print(f"âœ… Merged {len(dc_cols)} DC predictions")
    except Exception as e:
        print(f"âš ï¸ DC predictions failed: {e}")
    
    # Apply enhanced blending
    log_header("APPLY DYNAMIC BLENDING")
    df_out = _apply_blend(df_out)
    
    # Calculate confidence scores
    log_header("CALCULATE CONFIDENCE")
    df_out = calculate_confidence_scores(df_out)

    # Sort by Date, then League for better readability
    if 'Date' in df_out.columns:
        df_out['Date'] = pd.to_datetime(df_out['Date'], errors='coerce')
        df_out = df_out.sort_values(['Date', 'League'], ascending=[True, True])
        print("âœ… Sorted output by Date and League")

    # Save
    output_path = OUTPUT_DIR / "weekly_bets_lite.csv"
    df_out.to_csv(output_path, index=False)
    print(f"\nâœ… Saved predictions: {output_path}")
    
    # Generate HTML
    log_header("GENERATE REPORTS")
    onedrive_path = None  # Optional: set to custom path if needed
    _write_enhanced_html(df_out, OUTPUT_DIR, onedrive_path)
    
    # Summary
    print(f"\n{'='*60}")
    print(f"ðŸ“Š ULTIMATE PREDICTION SUMMARY")
    print(f"{'='*60}")
    print(f"Total matches: {len(df_out)}")
    print(f"Leagues: {df_out['League'].unique().tolist() if 'League' in df_out.columns else 'N/A'}")
    
    if 'AvgConfidence' in df_out.columns:
        high_conf = df_out[df_out['AvgConfidence'] > 0.7]
        print(f"High confidence (>70%): {len(high_conf)}")
        print(f"Average confidence: {df_out['AvgConfidence'].mean():.1%}")
    
    blend_cols = [c for c in df_out.columns if c.startswith('BLEND_')]
    print(f"BLEND predictions: {len(blend_cols)}")
    print(f"{'='*60}\n")
    
    return output_path

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--fixtures_csv", type=str, default="outputs/upcoming_fixtures.csv")
    args = parser.parse_args()
    
    predict_week(Path(args.fixtures_csv))